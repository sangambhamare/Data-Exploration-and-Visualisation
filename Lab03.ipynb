{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PmY8Xcqp0xy"
   },
   "source": [
    "# Lab session 3: Data Exploration and Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KR7EQbYp0x0"
   },
   "source": [
    "## Introduction \n",
    "\n",
    "The aim of this lab (Lab session 3) is for students to get experience with **Data Exploration** and **Data Visualisation**, both covered in lecture 4, by using typical Python libraries.\n",
    "\n",
    "\n",
    "This session starts with a tutorial that uses examples to introduce you to the practical knowledge that you will need for the corresponding assignment. We highly recommend that you read the following tutorials if you need a gentler introduction to the libraries that we use:\n",
    "- [Numpy quickstart tutorial](https://numpy.org/devdocs/user/quickstart.html)\n",
    "- [Numpy: basic broadcasting](https://numpy.org/doc/stable/user/basics.broadcasting.html)\n",
    "- [Pandas](https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html)\n",
    "- [Matplotlib](https://matplotlib.org/tutorials/introductory/pyplot.html)\n",
    "- [Seaborn](https://seaborn.pydata.org/tutorial/relational.html)\n",
    "- [Scikit-learn](https://scikit-learn.org/stable/tutorial/basic/tutorial.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1Oo7pF1p0x3"
   },
   "source": [
    "## 1 Exploring and visualising the graduation rate dataset\n",
    "\n",
    "\n",
    "In order to present typical Python functionalities for data exploration and data visualisation, we will use the graduation rate dataset (http://roycekimmons.com/tools/generated_data) as part of a working example.\n",
    "\n",
    "Note that this is a **synthetic** dataset that presents a familiar setting for the sake of simplicity. Therefore, this dataset should not be used to draw conclusions about students in the real world."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZ8fmvzJp0x3"
   },
   "source": [
    "### 1.1 Loading the graduation rate dataset\n",
    "\n",
    "The graduation rate dataset is stored in a file called ``graduation_rate.csv``, which can be found together with this notebook. You can inspect this file using any text editor. The file contains 1001 lines. The first line contains the name of the features, separated by commas. The remaining lines contain one observation per line. The values for the features of each observation are also separated by lines.\n",
    "\n",
    "The library ``pandas`` has a convenient function called ``read_csv``, which expects a file that follows the convention described above. This function returns a ``DataFrame``, which represents the data set.\n",
    "\n",
    "The function ``display`` used within a notebook is similar to the Python function ``print``, but presents a ``DataFrame`` in a much more convenient format. By default, only the first five rows and the last five rows of a large ``DataFrame`` are shown.\n",
    "\n",
    "This initial inspection reveals that most features are numerical, except for the feature ``parental level of education``, which has multiple text values. In order to display the valid values for this feature, we select the corresponding column from the ``DataFrame``, and use the method ``Series.unique``. This method returns the unique values across a ``Series``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OotsuBaqp0x5"
   },
   "outputs": [],
   "source": [
    "# Loading dataset (http://roycekimmons.com/tools/generated_data)\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('graduation_rate.csv')\n",
    "\n",
    "print('Dataset (head and tail):')\n",
    "display(df)\n",
    "\n",
    "print('\\nParental levels of education:')\n",
    "print(df['parental level of education'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "slCKCMOxp0x6"
   },
   "source": [
    "### 1.2 Pre-processing features\n",
    "\n",
    "In order to establish a natural ordering over ``parental level of education``, the corresponding column of the ``DataFrame`` is substituted by a column of ordinal features created using the function ``pd.Categorical``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnGYX8YXp0x6"
   },
   "outputs": [],
   "source": [
    "education_order = ['some high school', 'high school', 'some college', \"associate's degree\", \"bachelor's degree\", \"master's degree\"]\n",
    "\n",
    "df['parental level of education'] = pd.Categorical(df['parental level of education'],\n",
    "                                                   ordered=True,\n",
    "                                                   categories=education_order)\n",
    "\n",
    "display(df['parental level of education'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fsQQJ-a0p0x6"
   },
   "source": [
    "### 1.3 Data summarisation\n",
    "\n",
    "The method ``DataFrame.describe`` can be used to compute most of the univariate summaries that we have covered during the lectures. For each feature, this method computes the mean, standard deviation, minimum, maximum, median, lower quartile, and upper quartile. \n",
    "\n",
    "Note that ``DataFrame.describe`` detects and omits the categorical feature ``parental level of education``, since those summaries would not be useful. Instead, it is possible to use the method ``Series.value_counts`` to derive the frequency of each value of this feature.\n",
    "\n",
    "The method ``DataFrame.corr`` can be used to compute the correlation matrix for the (numerical) features in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0RCUorfNp0x7"
   },
   "outputs": [],
   "source": [
    "print('Univariate summaries:')\n",
    "display(df.describe())\n",
    "print(\"Frequency of parental levels of education:\")\n",
    "\n",
    "# relative frequency by dividing with len(df)\n",
    "freq_education = df['parental level of education'].value_counts()/len(df)\n",
    "display(freq_education)\n",
    "\n",
    "print(\"\\nCorrelation coefficients:\")\n",
    "display(df.corr(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oa7jaRI5p0x7"
   },
   "source": [
    "### 1.4 Table visualisation\n",
    "\n",
    "The method ``DataFrame.sort_values`` can be used to sort the rows of a ``DataFrame`` by the value of a specific feature, in ascending or descending order. For instance, we can use this method to sort students by ``college gpa``.\n",
    "\n",
    "We can also use **slicing** to select a range of observations from a ``DataFrame``. For example, we may sort the students by increasing ``parental income`` and then select the first ten students (with the lowest ``parental income``).\n",
    "\n",
    "When a ``DataFrame`` is indexed by a list of boolean values that has as many elements as the ``DataFrame`` has rows, only the rows that correspond to ``True`` values are returned. This also works when the list used for indexing is represented by a ``Series``. This functionality can be used to select rows that pass a test based on their features. For example, we may use it to select the students whose parents are educated beyond high school. \n",
    "\n",
    "The method ``DataFrame.groupby`` provides a simple way to partition observations into groups based on the value of chosen categorical features (for example, ``parental level of education``) and operating independently on each group (for example, computing the mean of the numerical features independently for each group)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KbAXorWZp0x8"
   },
   "outputs": [],
   "source": [
    "#print(df.to_latex()) # Print a table for use with LaTeX\n",
    "print('Sorting by college gpa:')\n",
    "display(df.sort_values(by='college gpa', ascending=False))\n",
    "\n",
    "print('Selecting the ten students with lowest parental income :')\n",
    "display(df.sort_values(by='parental income', ascending=True)[0:10])\n",
    "\n",
    "print('Sorting by high school gpa the students whose parents are educated beyond high school')\n",
    "# Note that a boolean sequence can be used to index a DataFrame\n",
    "display(df[df['parental level of education'] > 'high school'].sort_values(by='high school gpa', ascending=False))\n",
    "\n",
    "print('Grouping by parental level of education and computing the mean for other features:')\n",
    "display(df.groupby('parental level of education').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xG8nNhJp0x8"
   },
   "source": [
    "### 1.5 Histograms\n",
    "\n",
    "The library ``seaborn`` provides a high-level interface for drawing appealing graphics using ``matplotlib``.\n",
    "\n",
    "The following snippet is used to configure the appearance of ``seaborn`` graphics in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wY3eDA5Pp0x8"
   },
   "outputs": [],
   "source": [
    "%config InlineBackend.figure_formats = set(['retina'])\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbcc1O_dp0x8"
   },
   "source": [
    "The function ``histplot`` can be used to create a histogram with a specified number of bins for a given column of a ``DataFrame`` (or any list of numbers). For example, it may be used to create a histogram of ``high school gpa`` and ``college gpa``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MLQ_hJh7p0x9"
   },
   "outputs": [],
   "source": [
    "sns.histplot(df['high school gpa'])\n",
    "plt.title('Histogram: high school gpa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGmjyMnOp0x9"
   },
   "outputs": [],
   "source": [
    "sns.histplot(df['college gpa'])\n",
    "plt.title('Histogram: college gpa')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjPZkOWGp0x-"
   },
   "source": [
    "### 1.6 Pie charts\n",
    "\n",
    "The library ``seaborn`` currently has no function to create pie charts (likely due to the fact that this type of visualisation is often discouraged). The ``matplotlib`` function ``pie`` (``matplotlib.pyplot.pie``) can be used to depict an array of frequencies by a pie chart. For example, we may display the frequencies of ``parental level of education`` computed in the data summarization section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3impBKfp0x-"
   },
   "outputs": [],
   "source": [
    "plt.pie(freq_education, labels=freq_education.index)\n",
    "plt.title('Pie chart: parental level of education')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZmCukP72p0x-"
   },
   "source": [
    "### 1.7 Box Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_Ry_SJCp0x-"
   },
   "source": [
    "The function ``boxplot`` can be used to create a box plot for a specific feature. For example, it can be used to create a box plot for ``parental income``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q7mulB16p0x_"
   },
   "outputs": [],
   "source": [
    "sns.boxplot(df['parental income'], orient='v')\n",
    "plt.title('Boxplot: parental income')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSKierZSp0x_"
   },
   "source": [
    "The function ``boxplot`` is also capable of grouping observations by a categorical feature and creating one box plot for each resulting group. For example, we may create one box plot of ``parental income`` for each ``parental level of education``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UnaRGqEXp0x_"
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='parental level of education', y='parental income', data=df)\n",
    "plt.title('Boxplot: parental income, grouped by parental level of education')\n",
    "\n",
    "# Wrap xticks \n",
    "import textwrap\n",
    "ax.set_xticklabels([textwrap.fill(t.get_text(), 10)  for t in ax.get_xticklabels()])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZP1qk3Bp0x_"
   },
   "source": [
    "### 1.8 Scatter plots\n",
    "\n",
    "The function ``scatterplot`` can be used to create a scatter plot for any given pair of features, while the function ``pairplot`` can be used to create a scatter plot matrix. \n",
    "\n",
    "The resulting points can be coloured according to a categorical feature given by the parameter ``hue``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jcDnFjX-p0x_"
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='ACT composite score', y='SAT total score', data=df)\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(df, hue='parental level of education', diag_kind='hist')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xjziBMip0yA"
   },
   "source": [
    "### 1.9 Distance matrices\n",
    "\n",
    "In order to visualise a distance matrix, it is often important to group the observations in a dataset by a given categorical feature.\n",
    "\n",
    "For example, we may sort the observations by increasing ``parental level of education``. Because the feature ``parental level of education`` is ordinal but not numerical, we may also decide to remove it from consideration when computing distances between observations.\n",
    "\n",
    "Furthermore, it is always important to scale different features so that their magnitudes are comparable when computing distances. For example, we may use the ``sklearn`` class ``StandardScaler`` to standardize each feature individually. The method ``StandardScaler.fit_transform`` expects a numpy matrix containing observations across rows and returns a corresponding matrix with standardized features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y0e23lT6p0yA"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "df_sorted = df.sort_values(by='parental level of education', ascending=True)\n",
    "parental_education_sorted = df_sorted['parental level of education']\n",
    "\n",
    "X = df_sorted.drop(columns='parental level of education').to_numpy()\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yM7_tCtrp0yA"
   },
   "source": [
    "The ``scipy`` function ``pdist`` (``scipy.spatial.distance.pdist``) can be used to compute pairwise Euclidean distances between observations in a matrix, while the function ``squareform`` (``scipy.spatial.distance.squareform``) can be used to convert the return of ``pdist`` into the representation that we expect (``pdist`` returns a condensed representation of a symmetric matrix).\n",
    "\n",
    "Finally, the ``seaborn`` function ``heatmap`` can be used to create a heat map for the corresponding distance matrix (for a chosen colormap).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imyZdzzgp0yA"
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "dist = distance.squareform(distance.pdist(X))\n",
    "sns.heatmap(dist, square=True, xticklabels=False, yticklabels=False,\n",
    "                cmap='Blues')\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xas7AgYOp0yA"
   },
   "source": [
    "### 1.10 Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXXnzY6Zp0yB"
   },
   "source": [
    "The class ``MDS`` from the library ``sklearn`` implements dimensionality reduction through multidimensional scaling. A standardized matrix of observations as the one used to compute the distance matrix in the example above is an appropriate input to the method ``MDS.fit_transform``, which outputs a matrix that contains a two-dimensional point for each observation in the input matrix. A scatter plot can be used to depict this output matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rX9FPwhjp0yB"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS\n",
    "    \n",
    "embedding = MDS(n_components=2)\n",
    "    \n",
    "Xp = embedding.fit_transform(X)\n",
    "df_projection = pd.DataFrame({'x': Xp[:, 0], 'y': Xp[:, 1],\n",
    "                              'parental level of education': parental_education_sorted})\n",
    "\n",
    "sns.scatterplot(x='x', y='y', hue='parental level of education', data=df_projection)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RhyTbesIp0yB"
   },
   "source": [
    "The class ``TSNE`` from the library ``sklearn`` implements dimensionality reduction through t-distributed stochastic neighbour embedding (t-SNE). Its interface is analogous to the one provided by the class ``MDS``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E6umLwfzp0yB"
   },
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "embedding = TSNE(n_components=2, perplexity=100)\n",
    "\n",
    "Xp = embedding.fit_transform(X)\n",
    "df_projection = pd.DataFrame({'x': Xp[:, 0], 'y': Xp[:, 1],\n",
    "                              'parental level of education': parental_education_sorted})\n",
    "sns.scatterplot(x='x', y='y', hue='parental level of education', data=df_projection)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wTON7qMCp0yB"
   },
   "source": [
    "In the example below, each point obtained by t-SNE is coloured according to whether the parents of the corresponding student have a higher education degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7FqaxGQp0yB"
   },
   "outputs": [],
   "source": [
    "df_projection['parents have degree'] = (df['parental level of education'] > 'some college')\n",
    "sns.scatterplot(x='x', y='y', hue='parents have degree', data=df_projection)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVb7knSvp0yC"
   },
   "source": [
    "## 2 Visualising an analytic function\n",
    "\n",
    "In order to present Python functionalities related to visualising scalar fields and vector fields, we will use the analytic function $f: \\mathbb{R}^2 \\to \\mathbb{R}$ given by $f(x,y) = z = x^2 + y^2$ as a working example.\n",
    "\n",
    "The ``numpy`` function ``linspace`` can be used to create a list of evenly spaced numbers in a specified interval, while the function ``meshgrid`` can be used to create all possible combinations of numbers from two given lists of numbers. \n",
    "\n",
    "In our example, the function ``meshgrid`` returns two matrices. The first matrix replicates the numbers of the first list across rows. In our example, this matrix represents positions along the x-axis. The second matrix replicates the numbers of the second list across columns. In our example, this matrix represents positions along the y-axis.\n",
    "\n",
    "By applying elementwise operations that ultimately combine the two matrices, it is possible to evaluate a function of two variables on every element of a grid defined by the two lists of numbers generated by ``linspace``. The resulting dataset can also be represented by a ``DataFrame``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vEw0aNmQp0yC"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "x_range = np.linspace(-1, 1, 10)\n",
    "y_range = np.linspace(-1, 1, 10)\n",
    "\n",
    "# meshgrid: X[i, j] == x_range[j] and Y[i, j] == y_range[i]\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "# Z[i, j] == f(x_range[j], y_range[i])\n",
    "Z = X**2 + Y**2\n",
    "\n",
    "# Dataset representation\n",
    "df = pd.DataFrame({'x': X.reshape(-1), 'y': Y.reshape(-1), 'z = f(x,y)': Z.reshape(-1)})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYj4suSzp0yC"
   },
   "source": [
    "### 2.1 Heat maps\n",
    "\n",
    "The ``matplotlib`` function ``imshow`` can be used to create a heatmap through nearest neighbour interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JBbFO34ip0yC"
   },
   "outputs": [],
   "source": [
    "# Interpolation: point (x, y) is colored according to the value z of the nearest point in the dataset\n",
    "plt.imshow(Z, cmap='Blues', aspect='equal', interpolation='nearest')\n",
    "plt.colorbar()\n",
    "\n",
    "# xticks and yticks would show Z matrix indices\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VRHQgABNp0yC"
   },
   "source": [
    "The ``matplotlib`` function ``imshow`` can also be used to create a heatmap through bilinear interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SHHh6sREp0yD"
   },
   "outputs": [],
   "source": [
    "# Interpolation: point (x, y) is colored according to the (weighted average) value z of the four nearest points\n",
    "plt.imshow(Z, cmap='Blues', aspect='equal', interpolation='bilinear')\n",
    "plt.colorbar()\n",
    "\n",
    "# xticks and yticks would show Z matrix indices\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7CHy3kKp0yD"
   },
   "source": [
    "### 2.2 Contour plots\n",
    "\n",
    "The ``matplotlib`` function ``contour`` can be used to create a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HSuQr9PDp0yD"
   },
   "outputs": [],
   "source": [
    "CS = plt.contour(X, Y, Z, levels=10, cmap='Blues')\n",
    "plt.clabel(CS, inline=True, fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgHH7mV1p0yD"
   },
   "source": [
    "### 2.3 Surface plots\n",
    "\n",
    "The library ``matplotlib`` is also capable of creating (interactive) three-dimensional plots. Surface plots can be created using the function ``plot_surface``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA_cEFVZp0yD"
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(X, Y, Z, cmap='Blues', linewidth=0, antialiased=True)\n",
    "fig.colorbar(surf, shrink=0.5, aspect=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gboBGOq1p0yD"
   },
   "source": [
    "### 2.4 Quiver plots\n",
    "\n",
    "The ``matplotlib`` function ``quiver`` can be used to create quiver plots. For example, we may use the ``numpy`` function ``gradient`` to approximate the gradient function $\\nabla f$ of the scalar field $f$ by the finite differences method, which can then be represented by a quiver plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ba7XNF7bp0yE"
   },
   "outputs": [],
   "source": [
    "DY, DX = np.gradient(Z)\n",
    "plt.quiver(X, Y, DX, DY)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3A9QvCIf8--d"
   },
   "source": [
    "## Exercise\n",
    "\n",
    "\n",
    "\n",
    "Kaggle has a data-set of cars which can be downloaded  [here](https://www.kaggle.com/CooperUnion/cardataset). The csv file is named data.csv and can also be found in QM+. </br> \n",
    "It contains more than 10,000 rows and more than 10 columns of features of the car such as Engine Fuel Type, Engine HP, Transmission Type, highway MPG, city MPG. </br>\n",
    "Fill in the code below according to instructions-comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bLmaIfjd98-1"
   },
   "outputs": [],
   "source": [
    "# packages that will be needed\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns                       #visualisation\n",
    "import matplotlib.pyplot as plt             #visualisation\n",
    "%matplotlib inline     \n",
    "sns.set(color_codes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mv3ow2GyCRrL"
   },
   "outputs": [],
   "source": [
    "# 1) load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ctj_qrAlCQvB"
   },
   "outputs": [],
   "source": [
    "# 2) check types of features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Luq8587nCcfv"
   },
   "outputs": [],
   "source": [
    "# 3) drop the features: Engine Fuel Type,  Market Category, Vehicle Style, Popularity, Number of Doors and Vehicle Size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdYIrggeCfzy"
   },
   "outputs": [],
   "source": [
    "# 4) print number of duplicate rows and then remove them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l7574R_1CkHm"
   },
   "outputs": [],
   "source": [
    "# 5) print how many missing and null values exist per feature and then remove them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FL3ZDcJKCleG"
   },
   "outputs": [],
   "source": [
    "# 6) compute correlation between the features and then create its heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ORESRh23CnKs"
   },
   "source": [
    "Given the above heatmap what can you infer about the feature MSRP (i.e. price)? Do the results seem intuitive?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81EBU3fXFMq9"
   },
   "outputs": [],
   "source": [
    "# 7) in the steps above there is something that was not taken into account: outliers!\n",
    "#    create the boxplot for the feature MSRP (i.e. price) and check whether outliers exist\n",
    "#    remove the outliers of the whole dataset by utilizing the IQR of the boxplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p06mtKJmGZio"
   },
   "outputs": [],
   "source": [
    "# 8) compute again the correlation between the features and create its heatmap\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NCDVIPZFGHU"
   },
   "source": [
    "Given the above heatmap (after outliers have been removed), what can you infer now about the feature MSRP (i.e., price)? Which feature is shown to depend on others and this result seems intuitive?\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
